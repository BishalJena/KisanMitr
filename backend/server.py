from fastapi import FastAPI, APIRouter, HTTPException, Depends, status, UploadFile, File
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from fastapi.middleware.gzip import GZipMiddleware
from fastapi.middleware.trustedhost import TrustedHostMiddleware
from dotenv import load_dotenv
from starlette.middleware.cors import CORSMiddleware
from motor.motor_asyncio import AsyncIOMotorClient
import os
import logging
from pathlib import Path
from pydantic import BaseModel, Field, EmailStr
from typing import List, Optional, Dict, Any
import uuid
from datetime import datetime, timedelta, timezone
import jwt
import bcrypt
import httpx
import json
import time
import asyncio
from functools import lru_cache
import redis
from cachetools import TTLCache
import aiofiles

# Import backend modules
from database import get_database
from models import User, ChatMessage, Conversation
from cultural_context import CulturalContextManager
from conversational_memory import ConversationalMemory, FarmProfile
from agricultural_rag import AgriculturalRAG
from voice_stt_service import VoiceSTTService
from workflow_engine import WorkflowEngine
from metrics_system import MetricsSystem
from media_analysis import MediaAnalysisService, MediaAnalysis
from schemes_database import schemes_db
from marketplace_database import marketplace_db

ROOT_DIR = Path(__file__).parent
load_dotenv(ROOT_DIR / '.env')

<<<<<<< HEAD
# MongoDB connection with performance optimizations
mongo_url = os.environ['MONGO_URL']
client = AsyncIOMotorClient(
    mongo_url,
    maxPoolSize=50,  # Increased connection pool
    minPoolSize=10,
    maxIdleTimeMS=30000,
    serverSelectionTimeoutMS=5000,
    connectTimeoutMS=10000,
    socketTimeoutMS=20000
)
db = client[os.environ['DB_NAME']]
=======
# Database connection is handled in database.py
# Global database instance initialized on startup
db = None
>>>>>>> c7ba531 (Initial push: migrate local codebase to KisanMitr)

# Security
security = HTTPBearer()
JWT_SECRET = os.environ.get('JWT_SECRET', 'your-secret-key-change-in-production')
JWT_ALGORITHM = "HS256"
JWT_EXPIRATION_HOURS = 24

# API Keys
CEREBRAS_API_KEY = os.environ.get('CEREBRAS_API_KEY')
MCP_GATEWAY_URL = os.environ.get('MCP_GATEWAY_URL', 'http://165.232.190.215:8811')
MCP_GATEWAY_TOKEN = os.environ.get('MCP_GATEWAY_TOKEN')  # Bearer token for MCP Gateway
EXA_API_KEY = os.environ.get('EXA_API_KEY')
OPENROUTER_API_KEY = os.environ.get('OPENROUTER_API_KEY')

# Performance optimizations
# Enhanced caching system with multiple layers
response_cache = TTLCache(maxsize=2000, ttl=180)  # 3 minute TTL for responses
user_cache = TTLCache(maxsize=1000, ttl=1800)  # 30 minute TTL for users
conversation_cache = TTLCache(maxsize=5000, ttl=600)  # 10 minute TTL for conversations
tool_result_cache = TTLCache(maxsize=1500, ttl=900)  # 15 minute TTL for tool results
voice_cache = TTLCache(maxsize=500, ttl=300)  # 5 minute TTL for voice responses

# Redis connection will be initialized after logger is defined
redis_client = None

# Performance monitoring
request_times = []
MAX_REQUEST_HISTORY = 1000

def record_request_time(duration: float):
    """Record request time for performance monitoring"""
    global request_times
    request_times.append(duration)
    if len(request_times) > MAX_REQUEST_HISTORY:
        request_times = request_times[-MAX_REQUEST_HISTORY:]

def get_performance_stats():
    """Get current performance statistics"""
    if not request_times:
        return {"avg_response_time": 0, "requests_processed": 0}
    
    return {
        "avg_response_time": sum(request_times) / len(request_times),
        "min_response_time": min(request_times),
        "max_response_time": max(request_times),
        "requests_processed": len(request_times),
        "p95_response_time": sorted(request_times)[int(len(request_times) * 0.95)] if len(request_times) > 20 else 0
    }

# Create the main app with performance settings
app = FastAPI(
    title="Agentic Farmer Chatbot API",
    description="High-performance agricultural advisory API with Cerebras integration",
    version="2.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)
api_router = APIRouter(prefix="/api")

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Initialize Redis connection after logger is available
try:
    redis_url = os.environ.get('REDIS_URL', 'redis://localhost:6379')
    redis_client = redis.from_url(redis_url, decode_responses=True, socket_connect_timeout=5)
    redis_client.ping()  # Test connection
    logger.info("Redis connected successfully")
except Exception as e:
    logger.info(f"Redis not available, using in-memory cache only: {e}")
    redis_client = None

# ==================== Error Messages ====================

ERROR_MESSAGES = {
    "en": {
        "processing_error": "Sorry, I encountered an error while processing your request. Please try again.",
        "voice_processing_error": "Unable to process voice input. Please check your audio and try again.",
        "timeout_error": "Request timed out. Please try with a shorter message.",
        "authentication_error": "Authentication failed. Please log in again.",
        "rate_limit_error": "Too many requests. Please wait a moment before trying again.",
        "service_unavailable": "Service temporarily unavailable. Please try again later.",
        "invalid_input": "Invalid input provided. Please check your message and try again."
    },
    "hi": {
        "processing_error": "à¤•à¥à¤·à¤®à¤¾ à¤•à¤°à¥‡à¤‚, à¤†à¤ªà¤•à¥‡ à¤…à¤¨à¥à¤°à¥‹à¤§ à¤•à¥‹ à¤¸à¤‚à¤¸à¤¾à¤§à¤¿à¤¤ à¤•à¤°à¤¤à¥‡ à¤¸à¤®à¤¯ à¤à¤• à¤¤à¥à¤°à¥à¤Ÿà¤¿ à¤¹à¥à¤ˆà¥¤ à¤•à¥ƒà¤ªà¤¯à¤¾ à¤ªà¥à¤¨à¤ƒ à¤ªà¥à¤°à¤¯à¤¾à¤¸ à¤•à¤°à¥‡à¤‚à¥¤",
        "voice_processing_error": "à¤µà¥‰à¤¯à¤¸ à¤‡à¤¨à¤ªà¥à¤Ÿ à¤•à¥‹ à¤¸à¤‚à¤¸à¤¾à¤§à¤¿à¤¤ à¤•à¤°à¤¨à¥‡ à¤®à¥‡à¤‚ à¤…à¤¸à¤®à¤°à¥à¤¥à¥¤ à¤•à¥ƒà¤ªà¤¯à¤¾ à¤…à¤ªà¤¨à¤¾ à¤‘à¤¡à¤¿à¤¯à¥‹ à¤œà¤¾à¤‚à¤šà¥‡à¤‚ à¤”à¤° à¤ªà¥à¤¨à¤ƒ à¤ªà¥à¤°à¤¯à¤¾à¤¸ à¤•à¤°à¥‡à¤‚à¥¤",
        "timeout_error": "à¤…à¤¨à¥à¤°à¥‹à¤§ à¤•à¤¾ à¤¸à¤®à¤¯ à¤¸à¤®à¤¾à¤ªà¥à¤¤ à¤¹à¥‹ à¤—à¤¯à¤¾à¥¤ à¤•à¥ƒà¤ªà¤¯à¤¾ à¤›à¥‹à¤Ÿà¥‡ à¤¸à¤‚à¤¦à¥‡à¤¶ à¤•à¥‡ à¤¸à¤¾à¤¥ à¤ªà¥à¤°à¤¯à¤¾à¤¸ à¤•à¤°à¥‡à¤‚à¥¤",
        "authentication_error": "à¤ªà¥à¤°à¤®à¤¾à¤£à¥€à¤•à¤°à¤£ à¤µà¤¿à¤«à¤²à¥¤ à¤•à¥ƒà¤ªà¤¯à¤¾ à¤«à¤¿à¤° à¤¸à¥‡ à¤²à¥‰à¤— à¤‡à¤¨ à¤•à¤°à¥‡à¤‚à¥¤",
        "rate_limit_error": "à¤¬à¤¹à¥à¤¤ à¤¸à¤¾à¤°à¥‡ à¤…à¤¨à¥à¤°à¥‹à¤§à¥¤ à¤•à¥ƒà¤ªà¤¯à¤¾ à¤ªà¥à¤¨à¤ƒ à¤ªà¥à¤°à¤¯à¤¾à¤¸ à¤•à¤°à¤¨à¥‡ à¤¸à¥‡ à¤ªà¤¹à¤²à¥‡ à¤¥à¥‹à¤¡à¤¼à¤¾ à¤‡à¤‚à¤¤à¤œà¤¾à¤° à¤•à¤°à¥‡à¤‚à¥¤",
        "service_unavailable": "à¤¸à¥‡à¤µà¤¾ à¤…à¤¸à¥à¤¥à¤¾à¤¯à¥€ à¤°à¥‚à¤ª à¤¸à¥‡ à¤…à¤¨à¥à¤ªà¤²à¤¬à¥à¤§à¥¤ à¤•à¥ƒà¤ªà¤¯à¤¾ à¤¬à¤¾à¤¦ à¤®à¥‡à¤‚ à¤ªà¥à¤¨à¤ƒ à¤ªà¥à¤°à¤¯à¤¾à¤¸ à¤•à¤°à¥‡à¤‚à¥¤",
        "invalid_input": "à¤…à¤®à¤¾à¤¨à¥à¤¯ à¤‡à¤¨à¤ªà¥à¤Ÿ à¤ªà¥à¤°à¤¦à¤¾à¤¨ à¤•à¤¿à¤¯à¤¾ à¤—à¤¯à¤¾à¥¤ à¤•à¥ƒà¤ªà¤¯à¤¾ à¤…à¤ªà¤¨à¤¾ à¤¸à¤‚à¤¦à¥‡à¤¶ à¤œà¤¾à¤‚à¤šà¥‡à¤‚ à¤”à¤° à¤ªà¥à¤¨à¤ƒ à¤ªà¥à¤°à¤¯à¤¾à¤¸ à¤•à¤°à¥‡à¤‚à¥¤"
    },
    "pa": {
        "processing_error": "à¨®à¨¾à¨«à¨¼ à¨•à¨°à¨¨à¨¾, à¨¤à©à¨¹à¨¾à¨¡à©€ à¨¬à©‡à¨¨à¨¤à©€ à¨¨à©‚à©° à¨ªà©à¨°à©‹à¨¸à©ˆà¨¸ à¨•à¨°à¨¦à©‡ à¨¸à¨®à©‡à¨‚ à¨‡à©±à¨• à¨—à¨²à¨¤à©€ à¨¹à©‹à¨ˆà¥¤ à¨•à¨¿à¨°à¨ªà¨¾ à¨•à¨°à¨•à©‡ à¨¦à©à¨¬à¨¾à¨°à¨¾ à¨•à©‹à¨¸à¨¼à¨¿à¨¸à¨¼ à¨•à¨°à©‹à¥¤",
        "voice_processing_error": "à¨µà©Œà¨‡à¨¸ à¨‡à¨¨à¨ªà©à©±à¨Ÿ à¨¨à©‚à©° à¨ªà©à¨°à©‹à¨¸à©ˆà¨¸ à¨•à¨°à¨¨ à¨µà¨¿à©±à¨š à¨…à¨¸à¨®à¨°à©±à¨¥à¥¤ à¨•à¨¿à¨°à¨ªà¨¾ à¨•à¨°à¨•à©‡ à¨†à¨ªà¨£à¨¾ à¨†à¨¡à©€à¨“ à¨šà©ˆà©±à¨• à¨•à¨°à©‹ à¨…à¨¤à©‡ à¨¦à©à¨¬à¨¾à¨°à¨¾ à¨•à©‹à¨¸à¨¼à¨¿à¨¸à¨¼ à¨•à¨°à©‹à¥¤",
        "timeout_error": "à¨¬à©‡à¨¨à¨¤à©€ à¨¦à¨¾ à¨¸à¨®à¨¾à¨‚ à¨¸à¨®à¨¾à¨ªà¨¤ à¨¹à©‹ à¨—à¨¿à¨†à¥¤ à¨•à¨¿à¨°à¨ªà¨¾ à¨•à¨°à¨•à©‡ à¨›à©‹à¨Ÿà©‡ à¨¸à©°à¨¦à©‡à¨¸à¨¼ à¨¨à¨¾à¨² à¨•à©‹à¨¸à¨¼à¨¿à¨¸à¨¼ à¨•à¨°à©‹à¥¤",
        "authentication_error": "à¨ªà©à¨°à¨®à¨¾à¨£à¨¿à¨•à¨¤à¨¾ à¨…à¨¸à¨«à¨²à¥¤ à¨•à¨¿à¨°à¨ªà¨¾ à¨•à¨°à¨•à©‡ à¨¦à©à¨¬à¨¾à¨°à¨¾ à¨²à©Œà¨— à¨‡à¨¨ à¨•à¨°à©‹à¥¤",
        "rate_limit_error": "à¨¬à¨¹à©à¨¤ à¨¸à¨¾à¨°à©€à¨†à¨‚ à¨¬à©‡à¨¨à¨¤à©€à¨†à¨‚à¥¤ à¨•à¨¿à¨°à¨ªà¨¾ à¨•à¨°à¨•à©‡ à¨¦à©à¨¬à¨¾à¨°à¨¾ à¨•à©‹à¨¸à¨¼à¨¿à¨¸à¨¼ à¨•à¨°à¨¨ à¨¤à©‹à¨‚ à¨ªà¨¹à¨¿à¨²à¨¾à¨‚ à¨¥à©‹à©œà¨¾ à¨‡à©°à¨¤à¨œà¨¼à¨¾à¨° à¨•à¨°à©‹à¥¤",
        "service_unavailable": "à¨¸à©‡à¨µà¨¾ à¨…à¨¸à¨¥à¨¾à¨ˆ à¨¤à©Œà¨° 'à¨¤à©‡ à¨…à¨¨à©à¨ªà¨²à¨¬à¨§à¥¤ à¨•à¨¿à¨°à¨ªà¨¾ à¨•à¨°à¨•à©‡ à¨¬à¨¾à¨…à¨¦ à¨µà¨¿à©±à¨š à¨¦à©à¨¬à¨¾à¨°à¨¾ à¨•à©‹à¨¸à¨¼à¨¿à¨¸à¨¼ à¨•à¨°à©‹à¥¤",
        "invalid_input": "à¨…à¨µà©ˆà¨§ à¨‡à¨¨à¨ªà©à©±à¨Ÿ à¨ªà©à¨°à¨¦à¨¾à¨¨ à¨•à©€à¨¤à¨¾ à¨—à¨¿à¨†à¥¤ à¨•à¨¿à¨°à¨ªà¨¾ à¨•à¨°à¨•à©‡ à¨†à¨ªà¨£à¨¾ à¨¸à©°à¨¦à©‡à¨¸à¨¼ à¨šà©ˆà©±à¨• à¨•à¨°à©‹ à¨…à¨¤à©‡ à¨¦à©à¨¬à¨¾à¨°à¨¾ à¨•à©‹à¨¸à¨¼à¨¿à¨¸à¨¼ à¨•à¨°à©‹à¥¤"
    }
}

def get_error_message(error_key: str, language: str = "en") -> str:
    """Get localized error message"""
    return ERROR_MESSAGES.get(language, ERROR_MESSAGES["en"]).get(error_key, ERROR_MESSAGES["en"][error_key])

# ==================== Performance Helpers ====================

async def get_cached_response(cache_key: str) -> Optional[Dict[str, Any]]:
    """Get cached response from Redis or in-memory cache"""
    try:
        if redis_client:
            cached = redis_client.get(cache_key)
            if cached:
                return json.loads(cached)
        
        return response_cache.get(cache_key)
    except Exception as e:
        logger.debug(f"Cache retrieval error: {e}")
        return None

async def set_cached_response(cache_key: str, response: Dict[str, Any], ttl: int = 300):
    """Set cached response in Redis or in-memory cache"""
    try:
        if redis_client:
            redis_client.setex(cache_key, ttl, json.dumps(response))
        
        response_cache[cache_key] = response
    except Exception as e:
        logger.debug(f"Cache storage error: {e}")

def create_cache_key(user_id: str, message: str, language: str = "en") -> str:
    """Create a cache key for responses"""
    import hashlib
    # Normalize message for caching
    normalized = message.lower().strip()
    key_data = f"{user_id}:{normalized}:{language}"
    return f"response:{hashlib.md5(key_data.encode()).hexdigest()}"

async def get_conversation_from_cache(conversation_id: str, user_id: str) -> Optional[List[Dict]]:
    """Get conversation history from cache"""
    cache_key = f"conv:{conversation_id}:{user_id}"
    try:
        if redis_client:
            cached = redis_client.get(cache_key)
            if cached:
                return json.loads(cached)
        
        return conversation_cache.get(cache_key)
    except Exception as e:
        logger.debug(f"Conversation cache error: {e}")
        return None

async def cache_conversation(conversation_id: str, user_id: str, messages: List[Dict]):
    """Cache conversation history"""
    cache_key = f"conv:{conversation_id}:{user_id}"
    try:
        if redis_client:
            redis_client.setex(cache_key, 600, json.dumps(messages))
        
        conversation_cache[cache_key] = messages
    except Exception as e:
        logger.debug(f"Conversation cache storage error: {e}")

# ==================== Models ====================

class User(BaseModel):
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
<<<<<<< HEAD
    email: EmailStr
    password_hash: str
    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))

class UserCreate(BaseModel):
    email: EmailStr
    password: str

class UserLogin(BaseModel):
    email: EmailStr
    password: str
=======
    phone_number: str  # Indian phone number format: +91XXXXXXXXXX
    name: Optional[str] = None  # Optional farmer name
    location: Optional[str] = None  # Optional location for better recommendations
    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    last_login: Optional[datetime] = None
    is_verified: bool = False

class PhoneNumberRequest(BaseModel):
    phone_number: str  # Format: +91XXXXXXXXXX or 91XXXXXXXXXX

class OTPVerificationRequest(BaseModel):
    phone_number: str
    otp: str

class UserProfileUpdate(BaseModel):
    name: Optional[str] = None
    location: Optional[str] = None
>>>>>>> c7ba531 (Initial push: migrate local codebase to KisanMitr)

class Token(BaseModel):
    access_token: str
    token_type: str = "bearer"
    user_id: str
<<<<<<< HEAD
    email: str
=======
    phone_number: str
    is_new_user: bool = False

class OTPResponse(BaseModel):
    success: bool
    message: str
    expires_in: int = 300  # 5 minutes
>>>>>>> c7ba531 (Initial push: migrate local codebase to KisanMitr)

class ChatMessage(BaseModel):
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    user_id: str
    conversation_id: str  # Group messages by conversation
    content: str
    role: str  # 'user' or 'assistant'
    language: str = 'en'  # 'en' or 'hi'
    tools_used: Optional[List[str]] = None
    reasoning_steps: Optional[List[Dict[str, Any]]] = None
    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))

class Conversation(BaseModel):
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    user_id: str
    title: str
    last_message: str
    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    updated_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))

class ChatRequest(BaseModel):
    message: str
    conversation_id: Optional[str] = None

class VoiceRequest(BaseModel):
    audio_data: str  # Base64 encoded audio
    language: Optional[str] = None
    conversation_id: Optional[str] = None

class WorkflowStartRequest(BaseModel):
    workflow_id: str
    initial_data: Optional[Dict[str, Any]] = {}

class WorkflowStepRequest(BaseModel):
    instance_id: str
    step_id: str
    step_data: Optional[Dict[str, Any]] = {}
    conversation_history: Optional[List[Dict[str, str]]] = []

class ChatResponse(BaseModel):
    message: str
    conversation_id: Optional[str] = None
    language: Optional[str] = "en"
    tools_used: Optional[List[str]] = []
    reasoning_steps: Optional[List[Dict[str, Any]]] = []
    processing_time: Optional[float] = None
    cached: Optional[bool] = False

class ErrorResponse(BaseModel):
    error: str
    error_code: str
    message: str
    details: Optional[Dict[str, Any]] = None
    timestamp: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    
class LoadingResponse(BaseModel):
    status: str = "processing"
    message: str
    estimated_time: Optional[float] = None
    progress: Optional[int] = None  # 0-100
    conversation_id: Optional[str] = None
    tools_used: Optional[List[str]] = None
    reasoning_steps: Optional[List[Dict[str, Any]]] = None
    language: str

class VoiceResponse(BaseModel):
    message: str
    conversation_id: str
    language: str
    audio_file: Optional[str] = None
    audio_duration: Optional[float] = None
    speech_confidence: Optional[float] = None
    tools_used: List[str] = []
    processing_time: Optional[float] = None

<<<<<<< HEAD
=======
# ==================== OTP Service ====================

class OTPService:
    """Simple OTP service for phone number verification"""
    
    def __init__(self):
        self.otp_storage = {}  # In production, use Redis
        self.otp_expiry = 300  # 5 minutes
    
    def generate_otp(self, phone_number: str) -> str:
        """Generate mock OTP (always 7421 for development)"""
        otp = "7421"  # Fixed mock OTP for development
        
        # Store OTP with expiry
        self.otp_storage[phone_number] = {
            'otp': otp,
            'created_at': time.time(),
            'attempts': 0
        }
        
        return otp
    
    def verify_otp(self, phone_number: str, otp: str) -> bool:
        """Verify OTP"""
        if phone_number not in self.otp_storage:
            return False
        
        stored_data = self.otp_storage[phone_number]
        
        # Check expiry
        if time.time() - stored_data['created_at'] > self.otp_expiry:
            del self.otp_storage[phone_number]
            return False
        
        # Check attempts (max 3)
        if stored_data['attempts'] >= 3:
            del self.otp_storage[phone_number]
            return False
        
        # Verify OTP
        if stored_data['otp'] == otp:
            del self.otp_storage[phone_number]
            return True
        else:
            stored_data['attempts'] += 1
            return False
    
    async def send_otp_sms(self, phone_number: str, otp: str) -> bool:
        """Send OTP via SMS (mock implementation)"""
        # In production, integrate with Twilio, AWS SNS, or Indian SMS providers
        logger.info(f"ðŸ“± Mock SMS to {phone_number}: Your OTP is {otp}")
        
        # For development, always use mock OTP 7421
        print(f"ðŸ” Mock OTP sent to {phone_number}: {otp} (Use 7421 to verify)")
        return True

def normalize_phone_number(phone: str) -> str:
    """Normalize Indian phone number to +91XXXXXXXXXX format"""
    # Remove all non-digits
    digits = ''.join(filter(str.isdigit, phone))
    
    # Handle different formats
    if digits.startswith('91') and len(digits) == 12:
        return f"+{digits}"
    elif len(digits) == 10:
        return f"+91{digits}"
    else:
        raise ValueError("Invalid Indian phone number format")

def validate_indian_phone(phone: str) -> bool:
    """Validate Indian phone number"""
    try:
        normalized = normalize_phone_number(phone)
        # Check if it's a valid Indian mobile number (starts with +91 and has 10 digits after)
        return len(normalized) == 13 and normalized.startswith('+91')
    except:
        return False

# Initialize OTP service
otp_service = OTPService()

>>>>>>> c7ba531 (Initial push: migrate local codebase to KisanMitr)
# ==================== Auth Utilities ====================

def hash_password(password: str) -> str:
    password_bytes = password.encode('utf-8')
    salt = bcrypt.gensalt()
    hashed = bcrypt.hashpw(password_bytes, salt)
    return hashed.decode('utf-8')

def verify_password(plain_password: str, hashed_password: str) -> bool:
    password_bytes = plain_password.encode('utf-8')
    hashed_bytes = hashed_password.encode('utf-8')
    return bcrypt.checkpw(password_bytes, hashed_bytes)

<<<<<<< HEAD
def create_access_token(user_id: str, email: str) -> str:
    expire = datetime.now(timezone.utc) + timedelta(hours=JWT_EXPIRATION_HOURS)
    to_encode = {"user_id": user_id, "email": email, "exp": expire}
=======
def create_access_token(user_id: str, phone_number: str) -> str:
    expire = datetime.now(timezone.utc) + timedelta(hours=JWT_EXPIRATION_HOURS)
    to_encode = {"user_id": user_id, "phone_number": phone_number, "exp": expire}
>>>>>>> c7ba531 (Initial push: migrate local codebase to KisanMitr)
    encoded_jwt = jwt.encode(to_encode, JWT_SECRET, algorithm=JWT_ALGORITHM)
    return encoded_jwt

async def get_current_user(credentials: HTTPAuthorizationCredentials = Depends(security)) -> Dict[str, str]:
    try:
        token = credentials.credentials
        payload = jwt.decode(token, JWT_SECRET, algorithms=[JWT_ALGORITHM])
        user_id: str = payload.get("user_id")
<<<<<<< HEAD
        email: str = payload.get("email")
        if user_id is None or email is None:
            raise HTTPException(status_code=401, detail="Invalid authentication credentials")
        return {"user_id": user_id, "email": email}
=======
        phone_number: str = payload.get("phone_number")
        if user_id is None or phone_number is None:
            raise HTTPException(status_code=401, detail="Invalid authentication credentials")
        return {"user_id": user_id, "phone_number": phone_number}
>>>>>>> c7ba531 (Initial push: migrate local codebase to KisanMitr)
    except jwt.ExpiredSignatureError:
        raise HTTPException(status_code=401, detail="Token has expired")
    except jwt.JWTError:
        raise HTTPException(status_code=401, detail="Could not validate credentials")

# ==================== MCP & Cerebras Services ====================

class MCPGatewayClient:
    def __init__(self, base_url: str, auth_token: Optional[str] = None):
        self.base_url = base_url
        self.rpc_endpoint = f"{base_url}/rpc"
        self.tools_endpoint = f"{base_url}/tools"
        self.auth_token = auth_token
        
    def _get_headers(self) -> Dict[str, str]:
        """Get headers with authentication if available"""
        headers = {"Content-Type": "application/json"}
        if self.auth_token:
            headers["Authorization"] = f"Bearer {self.auth_token}"
        return headers
        
    async def _call_mcp_tool(self, tool_name: str, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """Generic MCP tool caller using JSON-RPC protocol"""
        try:
            async with httpx.AsyncClient(timeout=30.0) as client:
                # Use JSON-RPC 2.0 protocol for MCP Gateway
                payload = {
                    "jsonrpc": "2.0",
                    "id": 1,
                    "method": "tools/call",
                    "params": {
                        "name": tool_name,
                        "arguments": arguments
                    }
                }
                
                headers = self._get_headers()
                
                # Use direct tool endpoint (this MCP Gateway uses HTTP REST API)
                response = await client.post(
                    f"{self.tools_endpoint}/{tool_name}",
                    json=arguments,
                    headers=headers
                )
                response.raise_for_status()
                result = response.json()
                
                # Handle successful response
                if result.get("success"):
                    return result.get("data", result)
                else:
                    return {"error": result.get("error", "Unknown error")}
                    
        except Exception as e:
            logger.error(f"Error calling MCP tool {tool_name}: {e}")
            return {"error": str(e)}
    
    @lru_cache(maxsize=100)
    def _cache_key(self, state: str, commodity: str, district: str = "") -> str:
        """Generate cache key for crop price requests"""
        return f"crop_price_{state}_{commodity}_{district}"
    
    async def get_crop_price(self, state: str, commodity: str, district: Optional[str] = None) -> Dict[str, Any]:
        """Fetch crop prices from MCP Gateway using proper MCP protocol"""
        arguments = {"state": state, "commodity": commodity}
        # Always include district parameter (even if empty) as the API requires it
        arguments["district"] = district or ""
            
        result = await self._call_mcp_tool("crop-price", arguments)
        
        # Ensure consistent response format
        if "error" in result:
            return {"error": result["error"], "data": None}
        else:
            return {"data": result.get("data", result), "error": None}
    
    async def search_web(self, query: str, num_results: int = 5) -> Dict[str, Any]:
        """Search web using MCP Gateway EXA search with proper MCP protocol"""
        arguments = {
            "query": query,
            "num_results": num_results
        }
        
        # Don't pass API key in arguments - it should be configured in the MCP server
        result = await self._call_mcp_tool("search", arguments)
        
        # Ensure consistent response format
        if "error" in result:
            return {"error": result["error"], "results": []}
        else:
            return {"results": result.get("results", result.get("data", [])), "error": None}
    
    async def call_tool(self, tool_name: str, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """Generic method to call any MCP tool"""
        result = await self._call_mcp_tool(tool_name, arguments)
        
        # Ensure consistent response format
        if "error" in result:
            return {"error": result["error"], "data": None}
        else:
            return {"data": result.get("data", result), "error": None}
    
    async def health_check(self) -> Dict[str, Any]:
        """Check MCP Gateway health and available tools"""
        try:
            async with httpx.AsyncClient(timeout=10.0) as client:
                # Check gateway health
                health_response = await client.get(f"{self.base_url}/health")
                health_response.raise_for_status()
                
                # List available tools using JSON-RPC
                tools_payload = {
                    "jsonrpc": "2.0",
                    "id": 1,
                    "method": "list_tools"
                }
                
                tools_response = await client.post(
                    self.rpc_endpoint,
                    json=tools_payload,
                    headers=self._get_headers()
                )
                tools_response.raise_for_status()
                tools_result = tools_response.json()
                
                return {
                    "status": "healthy",
                    "gateway_health": health_response.json(),
                    "available_tools": tools_result.get("result", [])
                }
        except Exception as e:
            logger.error(f"MCP Gateway health check failed: {e}")
            return {"status": "unhealthy", "error": str(e)}

class CerebrasService:
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = "https://api.cerebras.ai/v1/chat/completions"
        self.model = "llama3.1-8b"
    
    async def generate_response(self, messages: List[Dict[str, str]]) -> str:
        """Generate response using Cerebras LLM"""
        try:
            async with httpx.AsyncClient(timeout=60.0) as client:
                response = await client.post(
                    self.base_url,
                    json={
                        "model": self.model,
                        "messages": messages,
                        "temperature": 0.7,
                        "max_tokens": 1024
                    },
                    headers={
                        "Authorization": f"Bearer {self.api_key}",
                        "Content-Type": "application/json"
                    }
                )
                response.raise_for_status()
                result = response.json()
                return result['choices'][0]['message']['content']
        except Exception as e:
            logger.error(f"Error generating response: {e}")
            raise HTTPException(status_code=500, detail=f"LLM generation failed: {str(e)}")

# Initialize services with proper error handling
try:
    mcp_client = MCPGatewayClient(MCP_GATEWAY_URL, MCP_GATEWAY_TOKEN)
    cerebras_service = CerebrasService(CEREBRAS_API_KEY)
    media_analysis_service = MediaAnalysisService(OPENROUTER_API_KEY) if OPENROUTER_API_KEY else None
    logger.info(f"Initialized MCP Gateway client for: {MCP_GATEWAY_URL}")
    if MCP_GATEWAY_TOKEN:
        logger.info("MCP Gateway authentication token configured")
    if media_analysis_service:
        logger.info("Media analysis service initialized with OpenRouter API")
except Exception as e:
    logger.error(f"Failed to initialize services: {e}")
    raise

# ==================== Agentic Reasoning System ====================

class AgenticChatService:
    def __init__(self, cerebras_service: CerebrasService, mcp_client: MCPGatewayClient, database):
        self.cerebras = cerebras_service
        self.mcp = mcp_client
        self.db = database
        # Enhanced reasoning system
        self.reasoning_chain = []
        self.performance_metrics = {}
        self.multi_agent_mode = True  # Enable enhanced reasoning
        # Cultural context manager for enhanced multilingual support
        self.cultural_context = CulturalContextManager()
        # Conversational memory for personalized advice
        self.conversational_memory = ConversationalMemory()
        # Agricultural RAG system for domain knowledge
        self.agricultural_rag = AgriculturalRAG()
        # Voice STT service for speech-to-text
        self.voice_stt_service = VoiceSTTService()
        # Workflow engine for agricultural process automation
        self.workflow_engine = WorkflowEngine(database, mcp_client, None)
        # Metrics system for performance and impact tracking
        self.metrics_system = MetricsSystem(database)
    
    async def analyze_task(self, user_message: str) -> Dict[str, Any]:
        """Step 1: Analyze the task and generate steps"""
        system_prompt = """You are an advanced agricultural AI assistant with multi-step reasoning capabilities.

IMPORTANT RULES:
1. ONLY respond to queries about: farming, agriculture, crops, livestock, soil, irrigation, pesticides, fertilizers, agricultural markets, farm equipment, weather impact on farming, crop diseases, etc.
2. If the query is NOT about farming/agriculture, respond with: {"is_agricultural": false, "language": "detected_language"}
3. For agricultural queries, determine tools needed and reasoning complexity:
   - crop-price: Current/recent market prices of crops
   - web-search: Recent news, current events, new research, time-sensitive information
   - soil-health: Soil analysis, NPK levels, pH testing, crop recommendations
   - weather: Weather forecasts, irrigation planning, pest risk alerts
   - pest-identifier: Pest/disease identification and treatment recommendations
   - mandi-price: Market price trends, predictions, best market recommendations
<<<<<<< HEAD
=======
   - scheme-tool: Crop damage, insurance claims, government relief schemes, compensation
>>>>>>> c7ba531 (Initial push: migrate local codebase to KisanMitr)
   - none: Use base LLM knowledge for general farming advice
4. Detect language: en, hi, ta, te, mr, bn, gu, kn, ml, pa
5. Determine reasoning complexity:
   - simple: Single tool or direct knowledge
   - moderate: 2-3 tools with basic correlation  
   - complex: Multiple tools with multi-step analysis and synthesis

Respond in JSON format:
{
  "is_agricultural": true/false,
  "language": "en|hi|ta|te|mr|bn|gu|kn|ml|pa",
  "complexity_level": "simple|moderate|complex",
  "reasoning_chain_depth": 1-5,
  "needs_crop_price": true/false,
  "needs_web_search": true/false,
  "needs_soil_health": true/false,
  "needs_weather": true/false,
  "needs_pest_identifier": true/false,
  "needs_mandi_price": true/false,
<<<<<<< HEAD
  "crop_price_params": {"state": "...", "commodity": "...", "district": "..."},
=======
  "needs_scheme_tool": true/false,
  "crop_price_params": {"state": "...", "commodity": "...", "district": "..."},
  "scheme_tool_params": {"damage_type": "...", "crop_type": "...", "state": "...", "district": "..."},
>>>>>>> c7ba531 (Initial push: migrate local codebase to KisanMitr)
  "search_query": "...",
  "reasoning_steps": ["step1", "step2", "step3"],
  "synthesis_requirements": ["correlation1", "correlation2"],
  "confidence": 0.0-1.0,
  "steps": ["step1", "step2", ...]
}

Examples:
- "Best practices for rice cultivation" â†’ needs_web_search: false (use base knowledge)
- "Latest news on wheat prices" â†’ needs_web_search: true (recent/current data)
- "Current price of cotton in Punjab" â†’ needs_crop_price: true
<<<<<<< HEAD
=======
- "My rice crop is damaged due to flood" â†’ needs_scheme_tool: true
- "Need help with crop insurance claim" â†’ needs_scheme_tool: true
>>>>>>> c7ba531 (Initial push: migrate local codebase to KisanMitr)
- "Tell me a joke" â†’ is_agricultural: false"""
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_message}
        ]
        
        response = await self.cerebras.generate_response(messages)
        
        try:
            # Extract JSON from response
            if "```json" in response:
                json_str = response.split("```json")[1].split("```")[0].strip()
            elif "```" in response:
                json_str = response.split("```")[1].split("```")[0].strip()
            else:
                json_str = response.strip()
            
            analysis = json.loads(json_str)
            return analysis
        except Exception as e:
            logger.error(f"Error parsing analysis: {e}, Response: {response}")
            # Default fallback
            return {
                "is_agricultural": True,
                "language": "en",
                "needs_crop_price": False,
                "needs_web_search": False,
                "search_query": "",
                "steps": ["Provide answer using base knowledge"]
            }
    
    async def execute_tools(self, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """Step 2: Execute selected tools"""
        tool_results = {}
        tools_used = []
        
        # Execute crop price tool
        if analysis.get("needs_crop_price") and analysis.get("crop_price_params"):
            params = analysis["crop_price_params"]
            if params.get("state") and params.get("commodity"):
                logger.info(f"Calling crop-price tool with params: {params}")
                result = await self.mcp.get_crop_price(
                    state=params["state"],
                    commodity=params["commodity"],
                    district=params.get("district")
                )
                logger.info(f"Crop-price tool result: {result}")
                
                # Only mark as used if we got meaningful data
                if result and not result.get("error") and result.get("data"):
                    # Check if we actually got records
                    data = result.get("data", {})
                    if isinstance(data, dict) and data.get("records") and len(data["records"]) > 0:
                        tool_results["crop_price"] = result
                        tools_used.append("crop-price")
                        logger.info("Crop-price tool returned data - marked as used")
                    else:
                        logger.info("Crop-price tool returned empty records - not marking as used")
                        tool_results["crop_price"] = {"error": "No price data available", "data": None}
                else:
                    logger.info(f"Crop-price tool failed or returned error: {result}")
                    tool_results["crop_price"] = result
        
        # Execute web search tool
        if analysis.get("needs_web_search") and analysis.get("search_query"):
            logger.info(f"Calling search tool with query: {analysis['search_query']}")
            result = await self.mcp.search_web(analysis["search_query"])
            logger.info(f"Search tool result: {result}")
            
            # Only mark as used if we got meaningful results
            if result and not result.get("error") and result.get("results"):
                results = result.get("results", [])
                if isinstance(results, list) and len(results) > 0:
                    tool_results["web_search"] = result
                    tools_used.append("exa-search")
                    logger.info("Search tool returned results - marked as used")
                else:
                    logger.info("Search tool returned empty results - not marking as used")
                    tool_results["web_search"] = {"error": "No search results available", "results": []}
            else:
                logger.info(f"Search tool failed or returned error: {result}")
                tool_results["web_search"] = result
        
        # Execute soil health tool
        if analysis.get("needs_soil_health"):
            params = analysis.get("soil_health_params", {})
            logger.info(f"Calling soil-health tool with params: {params}")
            result = await self.mcp.call_tool("soil-health", params)
            logger.info(f"Soil-health tool result: {result}")
            
            if result and not result.get("error"):
                tool_results["soil_health"] = result
                tools_used.append("soil-health")
                logger.info("Soil-health tool executed successfully")
            else:
                logger.info(f"Soil-health tool failed: {result}")
                tool_results["soil_health"] = result
        
        # Execute weather tool
        if analysis.get("needs_weather"):
            params = analysis.get("weather_params", {})
            logger.info(f"Calling weather tool with params: {params}")
            result = await self.mcp.call_tool("weather", params)
            logger.info(f"Weather tool result: {result}")
            
            if result and not result.get("error"):
                tool_results["weather"] = result
                tools_used.append("weather")
                logger.info("Weather tool executed successfully")
            else:
                logger.info(f"Weather tool failed: {result}")
                tool_results["weather"] = result
        
        # Execute pest identifier tool
        if analysis.get("needs_pest_identifier"):
            params = analysis.get("pest_identifier_params", {})
            logger.info(f"Calling pest-identifier tool with params: {params}")
            result = await self.mcp.call_tool("pest-identifier", params)
            logger.info(f"Pest-identifier tool result: {result}")
            
            if result and not result.get("error"):
                tool_results["pest_identifier"] = result
                tools_used.append("pest-identifier")
                logger.info("Pest-identifier tool executed successfully")
            else:
                logger.info(f"Pest-identifier tool failed: {result}")
                tool_results["pest_identifier"] = result
        
        # Execute mandi price tool
        if analysis.get("needs_mandi_price"):
            params = analysis.get("mandi_price_params", {})
            logger.info(f"Calling mandi-price tool with params: {params}")
            result = await self.mcp.call_tool("mandi-price", params)
            logger.info(f"Mandi-price tool result: {result}")
            
            if result and not result.get("error"):
                tool_results["mandi_price"] = result
                tools_used.append("mandi-price")
                logger.info("Mandi-price tool executed successfully")
            else:
                logger.info(f"Mandi-price tool failed: {result}")
                tool_results["mandi_price"] = result
        
<<<<<<< HEAD
=======
        # Execute scheme tool for crop damage assistance
        if analysis.get("needs_scheme_tool"):
            params = analysis.get("scheme_tool_params", {})
            logger.info(f"Calling scheme-tool with params: {params}")
            result = await self.mcp.call_tool("scheme-tool", params)
            logger.info(f"Scheme-tool result: {result}")
            
            if result and not result.get("error"):
                tool_results["scheme_tool"] = result
                tools_used.append("scheme-tool")
                logger.info("Scheme-tool executed successfully")
            else:
                logger.info(f"Scheme-tool failed: {result}")
                tool_results["scheme_tool"] = result
        
>>>>>>> c7ba531 (Initial push: migrate local codebase to KisanMitr)
        return {"results": tool_results, "tools_used": tools_used}
    
    async def synthesize_data(self, analysis: Dict[str, Any], tool_results: Dict[str, Any]) -> Dict[str, Any]:
        """Enhanced data synthesis with multi-agent reasoning"""
        start_time = time.time()
        
        # Check if we need advanced synthesis
        complexity = analysis.get("complexity_level", "simple")
        synthesis_requirements = analysis.get("synthesis_requirements", [])
        
        if complexity == "simple" or not synthesis_requirements:
            # Simple pass-through for basic queries
            return {
                "synthesized_data": tool_results,
                "correlations": [],
                "confidence": analysis.get("confidence", 0.8),
                "synthesis_type": "simple"
            }
        
        # Advanced synthesis for complex queries
        logger.info(f"Performing {complexity} data synthesis with requirements: {synthesis_requirements}")
        
        synthesis_prompt = f"""You are a data synthesis specialist for agricultural intelligence.

Your task: Analyze and correlate the following agricultural data to provide comprehensive insights.

Query Analysis:
- Complexity: {complexity}
- Language: {analysis.get('language', 'en')}
- Synthesis Requirements: {synthesis_requirements}

Available Data:
{json.dumps(tool_results, indent=2)}

Please provide a synthesis in JSON format:
{{
  "key_insights": ["insight1", "insight2", "insight3"],
  "data_correlations": [
    {{"source1": "tool1", "source2": "tool2", "correlation": "description", "confidence": 0.0-1.0}}
  ],
  "risk_factors": ["risk1", "risk2"],
  "opportunities": ["opportunity1", "opportunity2"],
  "confidence_score": 0.0-1.0,
  "synthesis_summary": "Brief summary of synthesized insights"
}}

Focus on practical agricultural insights that help farmers make better decisions."""

        try:
            messages = [
                {"role": "system", "content": synthesis_prompt}
            ]
            
            response = await self.cerebras.generate_response(messages)
            
            # Parse synthesis result
            try:
                if "```json" in response:
                    json_str = response.split("```json")[1].split("```")[0].strip()
                else:
                    json_str = response.strip()
                
                synthesis_result = json.loads(json_str)
                
                # Add performance metrics
                duration = time.time() - start_time
                synthesis_result["synthesis_duration"] = duration
                synthesis_result["synthesis_type"] = complexity
                
                logger.info(f"Data synthesis completed in {duration:.2f}s")
                return synthesis_result
                
            except json.JSONDecodeError:
                logger.warning("Failed to parse synthesis JSON, using fallback")
                return {
                    "synthesized_data": tool_results,
                    "correlations": [],
                    "confidence": 0.6,
                    "synthesis_type": "fallback",
                    "synthesis_duration": time.time() - start_time
                }
                
        except Exception as e:
            logger.error(f"Error in data synthesis: {e}")
            return {
                "synthesized_data": tool_results,
                "correlations": [],
                "confidence": 0.5,
                "synthesis_type": "error",
                "error": str(e),
                "synthesis_duration": time.time() - start_time
            }
    
    async def evaluate_and_respond(self, user_message: str, analysis: Dict[str, Any], tool_results: Dict[str, Any], conversation_history: List[Dict[str, str]], synthesis_result: Optional[Dict[str, Any]] = None) -> str:
        """Step 3: Evaluate progress and generate final response"""
        language = analysis.get("language", "en")
        
        language_map = {
            "en": "English",
            "hi": "Hindi (à¤¹à¤¿à¤‚à¤¦à¥€)",
            "ta": "Tamil (à®¤à®®à®¿à®´à¯)",
            "te": "Telugu (à°¤à±†à°²à±à°—à±)",
            "mr": "Marathi (à¤®à¤°à¤¾à¤ à¥€)",
            "bn": "Bengali (à¦¬à¦¾à¦‚à¦²à¦¾)",
            "gu": "Gujarati (àª—à«àªœàª°àª¾àª¤à«€)",
            "kn": "Kannada (à²•à²¨à³à²¨à²¡)",
            "ml": "Malayalam (à´®à´²à´¯à´¾à´³à´‚)",
            "pa": "Punjabi (à¨ªà©°à¨œà¨¾à¨¬à©€)"
        }
        
        response_language = language_map.get(language, "English")
        
        # Process tool results into natural language context
        context_info = ""
        tool_failures = []
        
        if tool_results.get("crop_price"):
            crop_data = tool_results["crop_price"]
            if crop_data.get("data") and not crop_data.get("error"):
                # Check if we have actual price records
                data = crop_data.get("data", {})
                if isinstance(data, dict) and data.get("records") and len(data["records"]) > 0:
                    context_info += f"Current crop price data: {crop_data['data']}\n"
                else:
                    tool_failures.append("crop price data is currently unavailable")
            else:
                tool_failures.append("crop price data could not be retrieved")
        
        if tool_results.get("web_search"):
            search_data = tool_results["web_search"]
            if search_data.get("results") and not search_data.get("error"):
                results = search_data.get("results", [])
                if isinstance(results, list) and len(results) > 0:
                    context_info += f"Recent agricultural research and information: {search_data['results']}\n"
                else:
                    tool_failures.append("web search returned no current results")
            else:
                tool_failures.append("web search could not be completed")
        
<<<<<<< HEAD
=======
        if tool_results.get("scheme_tool"):
            scheme_data = tool_results["scheme_tool"]
            if scheme_data.get("data") and not scheme_data.get("error"):
                data = scheme_data.get("data", {})
                farmer_situation = data.get("farmer_situation", {})
                recommendations = data.get("recommendations", [])
                
                context_info += f"ðŸš¨ CROP DAMAGE ASSISTANCE AVAILABLE:\n"
                context_info += f"Damage Type: {farmer_situation.get('damage_type', 'Unknown')}\n"
                context_info += f"Estimated Compensation: â‚¹{farmer_situation.get('estimated_compensation', 0):,}\n"
                context_info += f"Available Recommendations: {len(recommendations)}\n"
                
                # Add top recommendations
                if recommendations:
                    context_info += f"Top Recommendations:\n"
                    for i, rec in enumerate(recommendations[:3], 1):
                        context_info += f"{i}. {rec['action']} ({rec['priority']} priority)\n"
                        if rec.get('contact'):
                            context_info += f"   Contact: {rec['contact']}\n"
                
                # Add immediate actions
                action_plan = data.get("action_plan", {})
                immediate_actions = action_plan.get("immediate_actions", [])
                if immediate_actions:
                    context_info += f"Immediate Actions Required:\n"
                    for i, action in enumerate(immediate_actions[:3], 1):
                        context_info += f"{i}. {action}\n"
                
                # Add important contacts
                contacts = data.get("important_contacts", {})
                if contacts:
                    context_info += f"Important Helplines:\n"
                    context_info += f"PMFBY: {contacts.get('pmfby_helpline', 'N/A')}\n"
                    context_info += f"Kisan Call Center: {contacts.get('kisan_call_center', 'N/A')}\n"
                
                context_info += f"Scheme assistance data: {scheme_data['data']}\n"
            else:
                tool_failures.append("crop damage scheme assistance could not be retrieved")
        
>>>>>>> c7ba531 (Initial push: migrate local codebase to KisanMitr)
        # Add information about tool failures to help the AI respond appropriately
        if tool_failures:
            context_info += f"\nNote: The following data sources were attempted but unavailable: {', '.join(tool_failures)}. Please provide general agricultural guidance based on your knowledge.\n"
        
        # Add synthesis insights if available
        if synthesis_result and synthesis_result.get("synthesis_type") != "simple":
            synthesis_info = synthesis_result
            if synthesis_info.get("key_insights"):
                context_info += f"\nKey Insights from Data Analysis: {synthesis_info['key_insights']}\n"
            if synthesis_info.get("data_correlations"):
                context_info += f"Data Correlations Found: {synthesis_info['data_correlations']}\n"
            if synthesis_info.get("risk_factors"):
                context_info += f"Risk Factors to Consider: {synthesis_info['risk_factors']}\n"
            if synthesis_info.get("opportunities"):
                context_info += f"Opportunities Identified: {synthesis_info['opportunities']}\n"
        
        # Extract crop information from user message for RAG
        detected_crop = self._extract_crop_from_message(user_message)
        
        # Enhance context with RAG knowledge
<<<<<<< HEAD
        base_prompt = f"""You are a helpful agricultural AI assistant EXCLUSIVELY for farmers. 

CRITICAL: You MUST respond in {response_language}. Match the user's language EXACTLY.

You have access to real-time crop prices and agricultural research.
Be practical, empathetic, and provide actionable advice.
=======
        base_prompt = f"""You are a practical agricultural AI assistant for farmers. 

CRITICAL: You MUST respond in {response_language}. Match the user's language EXACTLY.

You have access to real-time crop prices and agricultural data.
Provide direct, actionable information that farmers can use immediately.
>>>>>>> c7ba531 (Initial push: migrate local codebase to KisanMitr)

{context_info if context_info else "Use your agricultural knowledge to provide helpful farming advice."}"""

        # Enhance with RAG knowledge
        enhanced_prompt = self.agricultural_rag.enhance_response_with_knowledge(
            user_message, base_prompt, detected_crop
        )
        
        system_prompt = enhanced_prompt + f"""

<<<<<<< HEAD
CRITICAL RESPONSE RULES - FOLLOW EXACTLY:
- Maximum 150 words
- NO markdown formatting (no **, __, ##, -, etc.)
- Use plain text only
- Write in simple sentences
- No bullet points or numbered lists
- Use natural paragraph breaks
- Be conversational and direct
- Respond ONLY in {response_language}

Example good response:
"The PM-KISAN scheme provides Rs 6,000 yearly to small farmers. The Soil Health Card helps with fertilizer recommendations. PMFBY offers crop insurance protection."

NEVER use formatting like **bold** or numbered lists."""
=======
FARMER-FRIENDLY RESPONSE FORMAT - FOLLOW EXACTLY:

For PRICE QUERIES:
- Start with current price range: "Wheat price: Rs X to Rs Y per quintal"
- Show 2-3 specific markets with prices
- Add one practical tip (best time to sell, market trends)
- Keep under 100 words

For FARMING ADVICE:
- Give direct answer first
- Add 1-2 specific steps to take
- Mention timing if relevant
- Keep practical and simple

FORMATTING RULES:
- NO markdown (no **, __, ##, -, etc.)
- Use plain text only
- Short, clear sentences
- Natural paragraph breaks
- Respond ONLY in {response_language}

Example price response:
"Wheat price in Punjab: Rs 2,100 to Rs 2,300 per quintal. Ludhiana mandi: Rs 2,250, Amritsar: Rs 2,200, Jalandhar: Rs 2,150. Prices are stable this week. Good time to sell if you have quality grain."

Be direct and helpful like talking to a neighbor farmer."""
>>>>>>> c7ba531 (Initial push: migrate local codebase to KisanMitr)
        
        messages = [
            {"role": "system", "content": system_prompt}
        ]
        
        # Add conversation history
        for msg in conversation_history[-6:]:  # Last 3 exchanges
            messages.append(msg)
        
        # Add current user message
        messages.append({"role": "user", "content": user_message})
        
        response = await self.cerebras.generate_response(messages)
        
        # Strip any markdown formatting that might have slipped through
        cleaned_response = self._clean_markdown(response)
        return cleaned_response
    
    def _clean_markdown(self, text: str) -> str:
        """Remove markdown formatting from text"""
        import re
        
        # Remove bold/italic formatting
        text = re.sub(r'\*\*(.*?)\*\*', r'\1', text)  # **bold**
        text = re.sub(r'\*(.*?)\*', r'\1', text)      # *italic*
        text = re.sub(r'__(.*?)__', r'\1', text)      # __bold__
        text = re.sub(r'_(.*?)_', r'\1', text)        # _italic_
        
        # Remove headers
        text = re.sub(r'^#{1,6}\s+', '', text, flags=re.MULTILINE)
        
        # Remove bullet points and numbered lists
        text = re.sub(r'^\s*[-*+]\s+', '', text, flags=re.MULTILINE)
        text = re.sub(r'^\s*\d+\.\s+', '', text, flags=re.MULTILINE)
        
        # Remove code blocks
        text = re.sub(r'```.*?```', '', text, flags=re.DOTALL)
        text = re.sub(r'`(.*?)`', r'\1', text)
        
        # Clean up extra whitespace
        text = re.sub(r'\n\s*\n\s*\n', '\n\n', text)  # Multiple newlines to double
        text = text.strip()
        
        return text
    
    def _extract_crop_from_message(self, message: str) -> Optional[str]:
        """Extract crop name from user message for RAG enhancement"""
        message_lower = message.lower()
        
        # Common crops in Indian agriculture
        crops = ["wheat", "rice", "cotton", "sugarcane", "maize", "bajra", "jowar", 
                "barley", "gram", "peas", "mustard", "groundnut", "soybean", 
                "tomato", "potato", "onion"]
        
        for crop in crops:
            if crop in message_lower:
                return crop
        
        return None
    
    async def process_message(self, user_message: str, conversation_history: List[Dict[str, str]]) -> Dict[str, Any]:
        """Enhanced agentic flow with multi-agent reasoning: analyze -> execute -> synthesize -> evaluate"""
        reasoning_steps = []
        start_time = time.time()
        
        # Step 1: Enhanced Query Analysis
        logger.info("Step 1: Enhanced query analysis...")
        analysis_start = time.time()
        analysis = await self.analyze_task(user_message)
        analysis_duration = time.time() - analysis_start
        
        reasoning_steps.append({
            "step": "enhanced_analysis", 
            "result": analysis,
            "duration": analysis_duration,
            "agent": "Query Analyzer"
        })
        
        # Check if query is agricultural
        if not analysis.get("is_agricultural", True):
            language = analysis.get("language", "en")
            rejection_messages = {
                "en": "I apologize, but I can only assist with farming and agricultural topics. Please ask me questions about crops, livestock, farming techniques, agricultural markets, or related farming matters.",
                "hi": "à¤®à¥à¤à¥‡ à¤–à¥‡à¤¦ à¤¹à¥ˆ, à¤²à¥‡à¤•à¤¿à¤¨ à¤®à¥ˆà¤‚ à¤•à¥‡à¤µà¤² à¤–à¥‡à¤¤à¥€ à¤”à¤° à¤•à¥ƒà¤·à¤¿ à¤µà¤¿à¤·à¤¯à¥‹à¤‚ à¤®à¥‡à¤‚ à¤¸à¤¹à¤¾à¤¯à¤¤à¤¾ à¤•à¤° à¤¸à¤•à¤¤à¤¾ à¤¹à¥‚à¤‚à¥¤ à¤•à¥ƒà¤ªà¤¯à¤¾ à¤®à¥à¤à¤¸à¥‡ à¤«à¤¸à¤²à¥‹à¤‚, à¤ªà¤¶à¥à¤§à¤¨, à¤–à¥‡à¤¤à¥€ à¤•à¥€ à¤¤à¤•à¤¨à¥€à¤•à¥‹à¤‚, à¤•à¥ƒà¤·à¤¿ à¤¬à¤¾à¤œà¤¾à¤°à¥‹à¤‚ à¤¯à¤¾ à¤¸à¤‚à¤¬à¤‚à¤§à¤¿à¤¤ à¤–à¥‡à¤¤à¥€ à¤•à¥‡ à¤®à¤¾à¤®à¤²à¥‹à¤‚ à¤•à¥‡ à¤¬à¤¾à¤°à¥‡ à¤®à¥‡à¤‚ à¤ªà¥à¤°à¤¶à¥à¤¨ à¤ªà¥‚à¤›à¥‡à¤‚à¥¤",
                "ta": "à®®à®©à¯à®©à®¿à®•à¯à®•à®µà¯à®®à¯, à®¨à®¾à®©à¯ à®µà®¿à®µà®šà®¾à®¯à®®à¯ à®®à®±à¯à®±à¯à®®à¯ à®µà¯‡à®³à®¾à®£à¯à®®à¯ˆ à®¤à¯Šà®Ÿà®°à¯à®ªà®¾à®© à®µà®¿à®·à®¯à®™à¯à®•à®³à®¿à®²à¯ à®®à®Ÿà¯à®Ÿà¯à®®à¯‡ à®‰à®¤à®µ à®®à¯à®Ÿà®¿à®¯à¯à®®à¯.",
                "te": "à°•à±à°·à°®à°¿à°‚à°šà°‚à°¡à°¿, à°¨à±‡à°¨à± à°µà±à°¯à°µà°¸à°¾à°¯à°‚ à°®à°°à°¿à°¯à± à°µà±à°¯à°µà°¸à°¾à°¯ à°…à°‚à°¶à°¾à°²à°²à±‹ à°®à°¾à°¤à±à°°à°®à±‡ à°¸à°¹à°¾à°¯à°‚ à°šà±‡à°¯à°—à°²à°¨à±.",
                "mr": "à¤®à¤¾à¤« à¤•à¤°à¤¾, à¤®à¥€ à¤«à¤•à¥à¤¤ à¤¶à¥‡à¤¤à¥€ à¤†à¤£à¤¿ à¤•à¥ƒà¤·à¥€ à¤µà¤¿à¤·à¤¯à¤¾à¤‚à¤®à¤§à¥à¤¯à¥‡ à¤®à¤¦à¤¤ à¤•à¤°à¥‚ à¤¶à¤•à¤¤à¥‹.",
                "bn": "à¦¦à§à¦ƒà¦–à¦¿à¦¤, à¦†à¦®à¦¿ à¦¶à§à¦§à§à¦®à¦¾à¦¤à§à¦° à¦•à§ƒà¦·à¦¿ à¦à¦¬à¦‚ à¦•à§ƒà¦·à¦¿ à¦¬à¦¿à¦·à¦¯à¦¼à§‡ à¦¸à¦¾à¦¹à¦¾à¦¯à§à¦¯ à¦•à¦°à¦¤à§‡ à¦ªà¦¾à¦°à¦¿à¥¤",
                "gu": "àª®àª¾àª« àª•àª°àª¶à«‹, àª¹à«àª‚ àª«àª•à«àª¤ àª–à«‡àª¤à«€ àª…àª¨à«‡ àª•à«ƒàª·àª¿ àªµàª¿àª·àª¯à«‹àª®àª¾àª‚ àª®àª¦àª¦ àª•àª°à«€ àª¶àª•à«àª‚ àª›à«àª‚.",
                "kn": "à²•à³à²·à²®à²¿à²¸à²¿, à²¨à²¾à²¨à³ à²•à³‡à²µà²² à²•à³ƒà²·à²¿ à²®à²¤à³à²¤à³ à²•à³ƒà²·à²¿ à²µà²¿à²·à²¯à²—à²³à²²à³à²²à²¿ à²®à²¾à²¤à³à²° à²¸à²¹à²¾à²¯ à²®à²¾à²¡à²¬à²²à³à²²à³†.",
                "ml": "à´•àµà´·à´®à´¿à´•àµà´•à´£à´‚, à´Žà´¨à´¿à´•àµà´•àµ à´•àµƒà´·à´¿à´¯àµà´‚ à´•à´¾àµ¼à´·à´¿à´• à´µà´¿à´·à´¯à´™àµà´™à´³à´¿à´²àµà´‚ à´®à´¾à´¤àµà´°à´®àµ‡ à´¸à´¹à´¾à´¯à´¿à´•àµà´•à´¾àµ» à´•à´´à´¿à´¯àµ‚.",
                "pa": "à¨®à¨¾à¨«à¨¼ à¨•à¨°à¨¨à¨¾, à¨®à©ˆà¨‚ à¨¸à¨¿à¨°à¨«à¨¼ à¨–à©‡à¨¤à©€à¨¬à¨¾à©œà©€ à¨…à¨¤à©‡ à¨–à©‡à¨¤à©€ à¨µà¨¿à¨¸à¨¼à¨¿à¨†à¨‚ à¨µà¨¿à©±à¨š à¨®à¨¦à¨¦ à¨•à¨° à¨¸à¨•à¨¦à¨¾ à¨¹à¨¾à¨‚à¥¤"
            }
            return {
                "message": rejection_messages.get(language, rejection_messages["en"]),
                "language": language,
                "tools_used": [],
                "reasoning_steps": reasoning_steps,
                "performance_metrics": {"total_duration": time.time() - start_time}
            }
        
        # Step 2: Tool Execution
        logger.info("Step 2: Executing tools...")
        execution_start = time.time()
        tool_execution = await self.execute_tools(analysis)
        execution_duration = time.time() - execution_start
        
        reasoning_steps.append({
            "step": "tool_execution", 
            "tools_used": tool_execution["tools_used"],
            "duration": execution_duration,
            "agent": "Tool Executor"
        })
        
        # Step 3: Data Synthesis (New!)
        complexity = analysis.get("complexity_level", "simple")
        if complexity in ["moderate", "complex"] and tool_execution["tools_used"]:
            logger.info(f"Step 3: Data synthesis for {complexity} query...")
            synthesis_start = time.time()
            synthesis_result = await self.synthesize_data(analysis, tool_execution["results"])
            synthesis_duration = time.time() - synthesis_start
            
            reasoning_steps.append({
                "step": "data_synthesis",
                "result": synthesis_result,
                "duration": synthesis_duration,
                "agent": "Data Synthesizer"
            })
        else:
            synthesis_result = {"synthesized_data": tool_execution["results"], "synthesis_type": "simple"}
        
        # Step 4: Enhanced Response Generation
        logger.info("Step 4: Generating enhanced response...")
        response_start = time.time()
        final_response = await self.evaluate_and_respond(
            user_message,
            analysis,
            synthesis_result.get("synthesized_data", tool_execution["results"]),
            conversation_history,
            synthesis_result
        )
        response_duration = time.time() - response_start
        
        reasoning_steps.append({
            "step": "response_generation", 
            "completed": True,
            "duration": response_duration,
            "agent": "Advisory Agent"
        })
        
        # Add model info if no tools were used
        tools_used = tool_execution["tools_used"]
        if not tools_used:
            tools_used = ["cerebras-llama-3.1-8b"]
        
        # Calculate total performance metrics
        total_duration = time.time() - start_time
        performance_metrics = {
            "total_duration": total_duration,
            "analysis_duration": analysis_duration,
            "execution_duration": execution_duration,
            "response_duration": response_duration,
            "complexity_level": complexity,
            "reasoning_chain_depth": len(reasoning_steps),
            "tools_count": len(tools_used),
            "cerebras_speed_advantage": f"{total_duration:.2f}s (sub-second agricultural advisory)"
        }
        
        # Add synthesis metrics if available
        if "synthesis_duration" in synthesis_result:
            performance_metrics["synthesis_duration"] = synthesis_result["synthesis_duration"]
        
        return {
            "message": final_response,
            "language": analysis.get("language", "en"),
            "tools_used": tools_used,
            "reasoning_steps": reasoning_steps,
            "performance_metrics": performance_metrics,
            "complexity_level": complexity,
            "confidence": analysis.get("confidence", 0.8)
        }

<<<<<<< HEAD
# Initialize agentic service
agentic_service = AgenticChatService(cerebras_service, mcp_client, db)

# ==================== API Routes ====================

@api_router.post("/auth/register", response_model=Token)
async def register(user_data: UserCreate):
    """Register a new user"""
    # Check if user exists
    existing_user = await db.users.find_one({"email": user_data.email})
    if existing_user:
        raise HTTPException(status_code=400, detail="Email already registered")
    
    # Create new user
    user = User(
        email=user_data.email,
        password_hash=hash_password(user_data.password)
    )
    
    user_dict = user.dict()
    user_dict['created_at'] = user_dict['created_at'].isoformat()
    
    await db.users.insert_one(user_dict)
    
    # Generate token
    access_token = create_access_token(user.id, user.email)
    
    return Token(
        access_token=access_token,
        user_id=user.id,
        email=user.email
    )

@api_router.post("/auth/login", response_model=Token)
async def login(credentials: UserLogin):
    """Login user"""
    user = await db.users.find_one({"email": credentials.email})
    
    if not user or not verify_password(credentials.password, user["password_hash"]):
        raise HTTPException(status_code=401, detail="Invalid email or password")
    
    access_token = create_access_token(user["id"], user["email"])
    
    return Token(
        access_token=access_token,
        user_id=user["id"],
        email=user["email"]
    )
=======
# Initialize agentic service (database will be retrieved dynamically)
agentic_service = AgenticChatService(cerebras_service, mcp_client, None)

# ==================== API Routes ====================

@api_router.post("/auth/send-otp", response_model=OTPResponse)
async def send_otp(request: PhoneNumberRequest):
    """Send OTP to phone number"""
    try:
        # Validate phone number
        if not validate_indian_phone(request.phone_number):
            raise HTTPException(status_code=400, detail="Invalid Indian phone number format")
        
        # Normalize phone number
        normalized_phone = normalize_phone_number(request.phone_number)
        
        # Generate and send OTP
        otp = otp_service.generate_otp(normalized_phone)
        await otp_service.send_otp_sms(normalized_phone, otp)
        
        return OTPResponse(
            success=True,
            message=f"OTP sent to {normalized_phone}",
            expires_in=300
        )
        
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        logger.error(f"Error sending OTP: {e}")
        raise HTTPException(status_code=500, detail="Failed to send OTP")

@api_router.post("/auth/verify-otp", response_model=Token)
async def verify_otp_and_login(request: OTPVerificationRequest):
    """Verify OTP and login/register user"""
    try:
        # Validate phone number
        if not validate_indian_phone(request.phone_number):
            raise HTTPException(status_code=400, detail="Invalid phone number format")
        
        # Normalize phone number
        normalized_phone = normalize_phone_number(request.phone_number)
        
        # Verify OTP
        if not otp_service.verify_otp(normalized_phone, request.otp):
            raise HTTPException(status_code=400, detail="Invalid or expired OTP")
        
        # Get database instance
        database = await get_database()
        
        # Check if user exists
        existing_user = await database.users.find_one({"phone_number": normalized_phone})
        
        if existing_user:
            # Existing user - update last login
            await database.users.update_one(
                {"phone_number": normalized_phone},
                {
                    "$set": {
                        "last_login": datetime.now(timezone.utc).isoformat(),
                        "is_verified": True
                    }
                }
            )
            
            # Generate token
            access_token = create_access_token(existing_user["id"], normalized_phone)
            
            return Token(
                access_token=access_token,
                user_id=existing_user["id"],
                phone_number=normalized_phone,
                is_new_user=False
            )
        else:
            # New user - create account
            user = User(
                phone_number=normalized_phone,
                is_verified=True,
                last_login=datetime.now(timezone.utc)
            )
            
            user_dict = user.dict()
            user_dict['created_at'] = user_dict['created_at'].isoformat()
            user_dict['last_login'] = user_dict['last_login'].isoformat()
            
            await database.users.insert_one(user_dict)
            
            # Generate token
            access_token = create_access_token(user.id, normalized_phone)
            
            return Token(
                access_token=access_token,
                user_id=user.id,
                phone_number=normalized_phone,
                is_new_user=True
            )
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error verifying OTP: {e}")
        raise HTTPException(status_code=500, detail="Verification failed")

@api_router.post("/auth/update-profile")
async def update_profile(profile_data: UserProfileUpdate, current_user: Dict = Depends(get_current_user)):
    """Update user profile information"""
    try:
        database = await get_database()
        
        update_data = {}
        if profile_data.name:
            update_data["name"] = profile_data.name
        if profile_data.location:
            update_data["location"] = profile_data.location
        
        if update_data:
            await database.users.update_one(
                {"id": current_user["user_id"]},
                {"$set": update_data}
            )
        
        return {"success": True, "message": "Profile updated successfully"}
        
    except Exception as e:
        logger.error(f"Error updating profile: {e}")
        raise HTTPException(status_code=500, detail="Failed to update profile")
>>>>>>> c7ba531 (Initial push: migrate local codebase to KisanMitr)

@api_router.get("/auth/me")
async def get_current_user_info(current_user: Dict = Depends(get_current_user)):
    """Get current user info"""
    return current_user

@api_router.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest, current_user: Dict = Depends(get_current_user)):
    """Send a message and get AI response with performance optimizations"""
    
    start_time = time.time()
    tools_used = []
    
    try:
        # Check cache for similar responses (for common questions)
        cache_key = create_cache_key(current_user["user_id"], request.message)
        cached_response = await get_cached_response(cache_key)
        
        if cached_response and len(request.message) > 10:  # Only cache longer queries
            logger.info(f"Cache hit for user {current_user['user_id']}")
            cached_response["conversation_id"] = request.conversation_id or str(uuid.uuid4())
            
            # Record cache hit metrics
            duration = time.time() - start_time
            record_request_time(duration)
            await agentic_service.metrics_system.record_request_metrics(
                start_time, "cache", "en", True
            )
            
            return ChatResponse(**cached_response)
        
        # Get or create conversation
        conversation_id = request.conversation_id
        if not conversation_id:
            conversation_id = str(uuid.uuid4())
            # Create new conversation asynchronously
            asyncio.create_task(create_conversation_async(
                conversation_id, current_user["user_id"], request.message
            ))
        
        # Get conversation history from cache first
        conversation_history = await get_conversation_from_cache(conversation_id, current_user["user_id"])
        
        if not conversation_history and conversation_id:
            # Fallback to database with optimized query
            messages = await db.chat_messages.find(
                {"conversation_id": conversation_id, "user_id": current_user["user_id"]},
                {"content": 1, "role": 1, "_id": 0}  # Only fetch needed fields
            ).sort("created_at", -1).limit(10).to_list(10)
            
            conversation_history = [
                {"role": msg["role"], "content": msg["content"]}
                for msg in reversed(messages)  # Reverse to get chronological order
            ]
            
            # Cache the conversation history
            await cache_conversation(conversation_id, current_user["user_id"], conversation_history)
        
        # Process message through agentic system
        result = await agentic_service.process_message(
            request.message,
            conversation_history or []
        )
        
        # Save messages asynchronously for better performance
        asyncio.create_task(save_chat_messages_async(
            current_user["user_id"], conversation_id, request.message, result
        ))
        
        # Cache response for similar future queries (only for informational responses)
        if not result.get("tools_used") and len(request.message) > 10:
            cache_response = {
                "message": result["message"],
                "language": result["language"],
                "tools_used": result["tools_used"],
                "reasoning_steps": result["reasoning_steps"]
            }
            asyncio.create_task(set_cached_response(cache_key, cache_response, 180))
        
        result["conversation_id"] = conversation_id
        
        # Record metrics
        tools_used = result.get("tools_used", [])
        primary_tool = tools_used[0] if tools_used else "cerebras-llama-3.1-8b"
        
        duration = time.time() - start_time
        record_request_time(duration)
        
        await agentic_service.metrics_system.record_request_metrics(
            start_time, primary_tool, result.get("language", "en"), True
        )
        
        return ChatResponse(**result)
    
    except Exception as e:
        logger.error(f"Error in chat: {e}")
        
        # Record error metrics
        duration = time.time() - start_time
        record_request_time(duration)
        
        await agentic_service.metrics_system.record_request_metrics(
            start_time, None, "en", False
        )
        
        # Determine language for error message
        error_language = "en"
        try:
            if hasattr(request, 'message') and request.message:
                # Simple language detection for error messages
                if any(char in request.message for char in 'à¤¹à¤¿à¤‚à¤¦à¥€à¤•à¥ƒà¤ªà¤¯à¤¾à¤•à¤°à¥‡à¤‚à¤®à¥‡à¤‚à¤•à¥‹à¤¸à¥‡'):
                    error_language = "hi"
                elif any(char in request.message for char in 'à¨ªà©°à¨œà¨¾à¨¬à©€à¨•à¨¿à¨°à¨ªà¨¾à¨•à¨°à¨•à©‡à¨µà¨¿à©±à¨šà¨¨à©‚à©°'):
                    error_language = "pa"
        except:
            pass
        
        error_msg = get_error_message("processing_error", error_language)
        raise HTTPException(
            status_code=500, 
            detail={
                "error": "processing_error",
                "message": error_msg,
                "language": error_language,
                "timestamp": datetime.now(timezone.utc).isoformat()
            }
        )

async def create_conversation_async(conversation_id: str, user_id: str, message: str):
    """Create conversation asynchronously"""
    try:
        conversation = Conversation(
            id=conversation_id,
            user_id=user_id,
            title=message[:50] + "..." if len(message) > 50 else message,
            last_message=message[:100]
        )
        conv_dict = conversation.dict()
        conv_dict['created_at'] = conv_dict['created_at'].isoformat()
        conv_dict['updated_at'] = conv_dict['updated_at'].isoformat()
        await db.conversations.insert_one(conv_dict)
    except Exception as e:
        logger.error(f"Error creating conversation: {e}")

async def save_chat_messages_async(user_id: str, conversation_id: str, user_message: str, ai_result: Dict):
    """Save chat messages asynchronously"""
    try:
        # Prepare messages for batch insert
        now = datetime.now(timezone.utc).isoformat()
        
        user_msg = {
            "id": str(uuid.uuid4()),
            "user_id": user_id,
            "conversation_id": conversation_id,
            "content": user_message,
            "role": "user",
            "language": ai_result.get("language", "en"),
            "tools_used": [],
            "created_at": now
        }
        
        assistant_msg = {
            "id": str(uuid.uuid4()),
            "user_id": user_id,
            "conversation_id": conversation_id,
            "content": ai_result["message"],
            "role": "assistant",
            "language": ai_result.get("language", "en"),
            "tools_used": ai_result.get("tools_used", []),
            "reasoning_steps": ai_result.get("reasoning_steps", []),
            "created_at": now
        }
        
        # Batch insert for better performance
        await db.chat_messages.insert_many([user_msg, assistant_msg])
        
        # Update conversation last message
        await db.conversations.update_one(
            {"id": conversation_id},
            {
                "$set": {
                    "last_message": user_message[:100],
                    "updated_at": now
                }
            }
        )
        
        # Invalidate conversation cache
        cache_key = f"conv:{conversation_id}:{user_id}"
        try:
            if redis_client:
                redis_client.delete(cache_key)
        except Exception as e:
            logger.debug(f"Redis cache deletion error: {e}")
        conversation_cache.pop(cache_key, None)
        
    except Exception as e:
        logger.error(f"Error saving messages: {e}")
        
        raise HTTPException(status_code=500, detail=str(e))


@api_router.post("/voice/transcribe")
async def transcribe_audio(
    request: VoiceRequest,
    current_user: Dict = Depends(get_current_user)
):
    """
    Transcribe audio using Deepgram Nova-2 STT
    Returns only the transcribed text (no AI response)
    """
    try:
        import base64
        start_time = time.time()
        
        # Decode audio data
        try:
            audio_bytes = base64.b64decode(request.audio_data)
        except Exception as e:
            raise HTTPException(status_code=400, detail=f"Invalid audio data: {e}")
        
        # Transcribe using Deepgram Nova-2
        result = await agentic_service.voice_stt_service.transcribe_audio(
            audio_bytes,
            language=request.language or "en"
        )
        
        if not result["success"]:
            raise HTTPException(status_code=400, detail=result.get("error", "Transcription failed"))
        
        processing_time = time.time() - start_time
        
        return {
            "success": True,
            "text": result["text"],
            "confidence": result["confidence"],
            "language": result["language"],
            "processing_time": processing_time
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error in audio transcription: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.get("/voice/capabilities")
async def get_voice_capabilities():
    """Get voice processing capabilities"""
    
    try:
        if not agentic_service.voice_stt_service.is_available():
            return {
                "available": False,
                "error": "Deepgram API key not configured"
            }
        
        return {
            "available": True,
            "model": "nova-2",
            "provider": "Deepgram",
            "supported_languages": agentic_service.voice_stt_service.get_supported_languages(),
            "features": ["smart_format", "punctuation", "multilingual"]
        }
        
    except Exception as e:
        logger.error(f"Error getting voice capabilities: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ==================== Media Attachment Endpoints ====================

@api_router.post("/media/upload")
async def upload_media(
    file: UploadFile = File(...),
    current_user: Dict = Depends(get_current_user)
):
    """Upload and analyze media files (images/documents)"""
    
    if not media_analysis_service:
        raise HTTPException(
            status_code=503, 
            detail="Media analysis service not available. Please configure OPENROUTER_API_KEY."
        )
    
    try:
        start_time = time.time()
        
        # Read file data
        file_data = await file.read()
        
        # Validate file
        validation = media_analysis_service.validate_file(file_data, file.filename)
        if not validation['valid']:
            raise HTTPException(status_code=400, detail=validation['error'])
        
        # Analyze based on file type
        if validation['file_type'] == 'image':
            analysis = await media_analysis_service.analyze_image(
                file_data, file.filename, current_user['user_id']
            )
        else:  # document
            analysis = await media_analysis_service.analyze_document(
                file_data, file.filename, current_user['user_id']
            )
        
        # Save analysis to database
        await db.media_analyses.insert_one(analysis.dict())
        
        # Record processing time
        processing_time = time.time() - start_time
        record_request_time(processing_time)
        
        return {
            "success": True,
            "analysis": analysis.dict(),
            "processing_time": processing_time
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error in media upload: {e}")
        raise HTTPException(status_code=500, detail=f"Media analysis failed: {str(e)}")

@api_router.get("/media/history")
async def get_media_history(
    limit: int = 10,
    current_user: Dict = Depends(get_current_user)
):
    """Get user's media analysis history"""
    
    try:
        analyses = await db.media_analyses.find(
            {"user_id": current_user["user_id"]},
            {"_id": 0}
        ).sort("created_at", -1).limit(limit).to_list(limit)
        
        return {"analyses": analyses}
        
    except Exception as e:
        logger.error(f"Error getting media history: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.get("/media/supported-formats")
async def get_supported_formats():
    """Get supported file formats and size limits"""
    
    return {
        "image_formats": ["jpeg", "jpg", "png", "webp", "heic"],
        "document_formats": ["pdf"],
        "max_image_size_mb": 10,
        "max_document_size_mb": 5
    }

# ==================== Schemes & Subsidies Endpoints ====================

class FarmerDetailsRequest(BaseModel):
    state: str
    district: str
    landSize: float
    cropTypes: List[str]

@api_router.post("/schemes/find")
async def find_schemes(
    farmer_details: FarmerDetailsRequest,
    current_user: Dict = Depends(get_current_user)
):
    """Find matching schemes based on farmer details"""
    try:
        # Convert to dict for processing
        farmer_data = farmer_details.dict()
        
        # Find matching schemes
        matching_schemes = schemes_db.find_matching_schemes(farmer_data)
        
        # Get enrollment status for each scheme
        user_id = current_user["user_id"]
        for scheme in matching_schemes:
            enrollment_status = schemes_db.generate_mock_enrollment_status(user_id, scheme["id"])
            scheme["enrollment_status"] = enrollment_status
        
        return {
            "success": True,
            "schemes": matching_schemes,
            "total_found": len(matching_schemes)
        }
        
    except Exception as e:
        logger.error(f"Error finding schemes: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.get("/schemes/enrollment/{user_id}")
async def get_enrollment_status(
    user_id: str,
    current_user: Dict = Depends(get_current_user)
):
    """Get mock enrollment status for all schemes"""
    try:
        # Verify user can access this data (either own data or admin)
        if user_id != current_user["user_id"]:
            raise HTTPException(status_code=403, detail="Access denied")
        
        enrollment_summary = schemes_db.get_user_enrollment_summary(user_id)
        
        return {
            "success": True,
            "enrollment_summary": enrollment_summary
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error getting enrollment status: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.get("/schemes/all")
async def get_all_schemes(current_user: Dict = Depends(get_current_user)):
    """Get all available schemes"""
    try:
        all_schemes = schemes_db.get_all_schemes()
        
        return {
            "success": True,
            "schemes": all_schemes,
            "total_schemes": len(all_schemes)
        }
        
    except Exception as e:
        logger.error(f"Error getting all schemes: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.get("/schemes/{scheme_id}")
async def get_scheme_details(
    scheme_id: str,
    current_user: Dict = Depends(get_current_user)
):
    """Get detailed information about a specific scheme"""
    try:
        scheme = schemes_db.schemes.get(scheme_id)
        if not scheme:
            raise HTTPException(status_code=404, detail="Scheme not found")
        
        # Add enrollment status for current user
        user_id = current_user["user_id"]
        enrollment_status = schemes_db.generate_mock_enrollment_status(user_id, scheme_id)
        scheme_with_status = scheme.copy()
        scheme_with_status["enrollment_status"] = enrollment_status
        
        return {
            "success": True,
            "scheme": scheme_with_status
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error getting scheme details: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ==================== Surplus Marketplace Endpoints ====================

class SurplusListingRequest(BaseModel):
    cropType: str
    quantity: float
    pricePerUnit: float
    readyDate: str
    qualityGrade: str
    description: Optional[str] = ""

class ListingUpdateRequest(BaseModel):
    cropType: Optional[str] = None
    quantity: Optional[float] = None
    pricePerUnit: Optional[float] = None
    readyDate: Optional[str] = None
    qualityGrade: Optional[str] = None
    description: Optional[str] = None
    status: Optional[str] = None

@api_router.post("/surplus/create")
async def create_surplus_listing(
    listing_data: SurplusListingRequest,
    current_user: Dict = Depends(get_current_user)
):
    """Create a new surplus listing"""
    try:
        user_id = current_user["user_id"]
        
        # Create listing
        listing = marketplace_db.create_listing(user_id, listing_data.dict())
        
        return {
            "success": True,
            "listing": listing,
            "message": "Surplus listing created successfully"
        }
        
    except Exception as e:
        logger.error(f"Error creating surplus listing: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.get("/surplus/user/{user_id}")
async def get_user_surplus_listings(
    user_id: str,
    current_user: Dict = Depends(get_current_user)
):
    """Get all surplus listings for a user"""
    try:
        # Verify user can access this data
        if user_id != current_user["user_id"]:
            raise HTTPException(status_code=403, detail="Access denied")
        
        listings = marketplace_db.get_user_listings(user_id)
        
        return {
            "success": True,
            "listings": listings,
            "total_listings": len(listings)
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error getting user listings: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.put("/surplus/{listing_id}")
async def update_surplus_listing(
    listing_id: str,
    updates: ListingUpdateRequest,
    current_user: Dict = Depends(get_current_user)
):
    """Update a surplus listing"""
    try:
        user_id = current_user["user_id"]
        
        # Filter out None values
        update_data = {k: v for k, v in updates.dict().items() if v is not None}
        
        updated_listing = marketplace_db.update_listing(listing_id, user_id, update_data)
        
        if not updated_listing:
            raise HTTPException(status_code=404, detail="Listing not found or access denied")
        
        return {
            "success": True,
            "listing": updated_listing,
            "message": "Listing updated successfully"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error updating listing: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.delete("/surplus/{listing_id}")
async def delete_surplus_listing(
    listing_id: str,
    current_user: Dict = Depends(get_current_user)
):
    """Delete a surplus listing"""
    try:
        user_id = current_user["user_id"]
        
        success = marketplace_db.delete_listing(listing_id, user_id)
        
        if not success:
            raise HTTPException(status_code=404, detail="Listing not found or access denied")
        
        return {
            "success": True,
            "message": "Listing deleted successfully"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error deleting listing: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.get("/surplus/stats")
async def get_marketplace_stats(current_user: Dict = Depends(get_current_user)):
    """Get marketplace statistics"""
    try:
        stats = marketplace_db.get_marketplace_stats()
        
        return {
            "success": True,
            "stats": stats
        }
        
    except Exception as e:
        logger.error(f"Error getting marketplace stats: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ==================== Workflow Automation Endpoints ====================

@api_router.get("/workflows/available")
async def get_available_workflows(current_user: Dict = Depends(get_current_user)):
    """Get list of available workflow templates"""
    
    try:
        workflows = agentic_service.workflow_engine.get_available_workflows()
        return {"workflows": workflows}
        
    except Exception as e:
        logger.error(f"Error getting available workflows: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.post("/workflows/start")
async def start_workflow(
    request: WorkflowStartRequest,
    current_user: Dict = Depends(get_current_user)
):
    """Start a new workflow instance"""
    
    try:
        result = await agentic_service.workflow_engine.start_workflow(
            request.workflow_id,
            current_user["user_id"],
            request.initial_data
        )
        
        if result["success"]:
            return result
        else:
            raise HTTPException(status_code=400, detail=result["error"])
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error starting workflow: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.post("/workflows/execute-step")
async def execute_workflow_step(
    request: WorkflowStepRequest,
    current_user: Dict = Depends(get_current_user)
):
    """Execute a specific step in a workflow"""
    
    try:
        result = await agentic_service.workflow_engine.execute_workflow_step(
            request.instance_id,
            request.step_id,
            request.step_data
        )
        
        if result["success"]:
            return result
        else:
            raise HTTPException(status_code=400, detail=result["error"])
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error executing workflow step: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.get("/workflows/user")
async def get_user_workflows(current_user: Dict = Depends(get_current_user)):
    """Get all workflow instances for current user"""
    
    try:
        workflows = await agentic_service.workflow_engine.get_user_workflows(
            current_user["user_id"]
        )
        return {"workflows": workflows}
        
    except Exception as e:
        logger.error(f"Error getting user workflows: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.get("/workflows/{instance_id}")
async def get_workflow_instance(
    instance_id: str,
    current_user: Dict = Depends(get_current_user)
):
    """Get specific workflow instance details"""
    
    try:
        # Check if user owns this workflow instance
        if instance_id in agentic_service.workflow_engine.user_workflow_instances:
            workflow = agentic_service.workflow_engine.user_workflow_instances[instance_id]
            
            if workflow.user_id != current_user["user_id"]:
                raise HTTPException(status_code=403, detail="Access denied")
            
            return {
                "workflow": agentic_service.workflow_engine._serialize_workflow(workflow),
                "next_step": agentic_service.workflow_engine._get_next_step(workflow)
            }
        else:
            raise HTTPException(status_code=404, detail="Workflow instance not found")
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error getting workflow instance: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ==================== Performance and Metrics Endpoints ====================

@api_router.get("/metrics/dashboard")
async def get_metrics_dashboard(current_user: Dict = Depends(get_current_user)):
    """Get comprehensive metrics dashboard"""
    
    try:
        dashboard_data = agentic_service.metrics_system.get_comprehensive_dashboard()
        return dashboard_data
        
    except Exception as e:
        logger.error(f"Error getting metrics dashboard: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.get("/metrics/performance")
async def get_performance_metrics(current_user: Dict = Depends(get_current_user)):
    """Get detailed performance metrics"""
    
    try:
        performance_data = agentic_service.metrics_system.performance.get_performance_summary()
        return {"performance": performance_data}
        
    except Exception as e:
        logger.error(f"Error getting performance metrics: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.get("/metrics/impact")
async def get_impact_metrics(current_user: Dict = Depends(get_current_user)):
    """Get agricultural impact metrics"""
    
    try:
        impact_data = agentic_service.metrics_system.impact.get_impact_summary()
        return {"impact": impact_data}
        
    except Exception as e:
        logger.error(f"Error getting impact metrics: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.get("/metrics/cerebras-showcase")
async def get_cerebras_showcase_metrics():
    """Get metrics showcasing Cerebras performance advantages - Public endpoint"""
    
    try:
        cerebras_data = agentic_service.metrics_system.get_cerebras_showcase_metrics()
        return cerebras_data
        
    except Exception as e:
        logger.error(f"Error getting Cerebras showcase metrics: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.get("/metrics/comparison")
async def get_comparison_metrics(current_user: Dict = Depends(get_current_user)):
    """Get system vs traditional comparison metrics"""
    
    try:
        comparison_data = agentic_service.metrics_system.comparison.get_comparison_summary()
        return {"comparison": comparison_data}
        
    except Exception as e:
        logger.error(f"Error getting comparison metrics: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.get("/metrics/report")
async def generate_performance_report(
    days: int = 7,
    current_user: Dict = Depends(get_current_user)
):
    """Generate comprehensive performance report"""
    
    try:
        report_data = await agentic_service.metrics_system.generate_performance_report(days)
        return {"report": report_data}
        
    except Exception as e:
        logger.error(f"Error generating performance report: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.post("/metrics/impact/record")
async def record_impact_metric(
    impact_type: str,
    value: float,
    category: str,
    current_user: Dict = Depends(get_current_user)
):
    """Record agricultural impact metric"""
    
    try:
        await agentic_service.metrics_system.record_agricultural_impact(
            impact_type, value, current_user["user_id"], category
        )
        
        return {"success": True, "message": "Impact metric recorded"}
        
    except Exception as e:
        logger.error(f"Error recording impact metric: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.get("/chat/history")
async def get_chat_history(
    current_user: Dict = Depends(get_current_user), 
    conversation_id: Optional[str] = None,
    limit: int = 50
):
    """Get chat history for current user or specific conversation"""
    query = {"user_id": current_user["user_id"]}
    if conversation_id:
        query["conversation_id"] = conversation_id
    
    messages = await db.chat_messages.find(query).sort("created_at", -1).limit(limit).to_list(limit)
    
    # Reverse to get chronological order
    messages.reverse()
    
    return [{"id": msg["id"], "content": msg["content"], "role": msg["role"], 
             "conversation_id": msg.get("conversation_id"),
             "language": msg["language"], "tools_used": msg.get("tools_used"),
             "created_at": msg["created_at"]} for msg in messages]

@api_router.get("/conversations")
async def get_conversations(current_user: Dict = Depends(get_current_user)):
    """Get all conversations for current user"""
    conversations = await db.conversations.find(
        {"user_id": current_user["user_id"]}
    ).sort("updated_at", -1).to_list(100)
    
    result = []
    for conv in conversations:
        result.append({
            "id": conv.get("id"),
            "title": conv.get("title", "Untitled"),
            "last_message": conv.get("last_message", ""),
            "created_at": conv.get("created_at", ""),
            "updated_at": conv.get("updated_at", "")
        })
    return result

@api_router.delete("/conversations/{conversation_id}")
async def delete_conversation(conversation_id: str, current_user: Dict = Depends(get_current_user)):
    """Delete a conversation and all its messages"""
    try:
        # Check if conversation belongs to current user
        conversation = await db.conversations.find_one({
            "id": conversation_id,
            "user_id": current_user["user_id"]
        })
        
        if not conversation:
            raise HTTPException(status_code=404, detail="Conversation not found")
        
        # Delete all messages in the conversation
        await db.chat_messages.delete_many({
            "conversation_id": conversation_id,
            "user_id": current_user["user_id"]
        })
        
        # Delete the conversation
        await db.conversations.delete_one({
            "id": conversation_id,
            "user_id": current_user["user_id"]
        })
        
        return {"message": "Conversation deleted successfully"}
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error deleting conversation: {e}")
        raise HTTPException(status_code=500, detail="Failed to delete conversation")


@api_router.get("/")
async def root():
    return {"message": "Agentic Farmer Chatbot API", "status": "running"}

@api_router.get("/health")
async def health_check():
    """Comprehensive health check including MCP Gateway connectivity"""
    try:
        # Check MCP Gateway health
        mcp_health = await mcp_client.health_check()
        
        return {
            "status": "healthy",
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "services": {
                "api": "running",
                "database": "connected",
                "mcp_gateway": mcp_health
            },
            "mcp_gateway_url": MCP_GATEWAY_URL,
            "features": {
                "multi_agent_reasoning": True,
                "cerebras_llama_3_1": True,
                "mcp_tool_orchestration": True,
                "multilingual_support": True
            }
        }
    except Exception as e:
        logger.error(f"Health check failed: {e}")
        return {
            "status": "degraded",
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "error": str(e),
            "mcp_gateway_url": MCP_GATEWAY_URL
        }

@api_router.get("/health")
async def health_check():
    """System health check endpoint"""
    try:
        # Check database connection
        db_status = "healthy"
        try:
<<<<<<< HEAD
            await db.command("ping")
=======
            database = await get_database()
            if hasattr(database, 'command'):
                await database.command("ping")
            else:
                db_status = "mock_database"
>>>>>>> c7ba531 (Initial push: migrate local codebase to KisanMitr)
        except Exception as e:
            db_status = f"unhealthy: {str(e)}"
        
        # Check Redis connection
        redis_status = "healthy" if redis_client else "not_configured"
        if redis_client:
            try:
                redis_client.ping()
            except Exception as e:
                redis_status = f"unhealthy: {str(e)}"
        
        # Check MCP Gateway
        mcp_status = "unknown"
        try:
            async with httpx.AsyncClient(timeout=5.0) as client:
                response = await client.get(f"{MCP_GATEWAY_URL}/health")
                mcp_status = "healthy" if response.status_code == 200 else f"unhealthy: {response.status_code}"
        except Exception as e:
            mcp_status = f"unhealthy: {str(e)}"
        
        # Get performance stats
        perf_stats = get_performance_stats()
        
        overall_status = "healthy"
        if "unhealthy" in db_status or "unhealthy" in mcp_status:
            overall_status = "degraded"
        
        return {
            "status": overall_status,
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "version": "2.0.0",
            "services": {
                "database": db_status,
                "redis": redis_status,
                "mcp_gateway": mcp_status
            },
            "performance": {
                "avg_response_time": round(perf_stats["avg_response_time"], 3),
                "requests_processed": perf_stats["requests_processed"],
                "cache_hit_rate": len(response_cache) / max(perf_stats["requests_processed"], 1)
            },
            "features": {
                "voice_processing": True,
                "multilingual_support": True,
                "workflow_automation": True,
                "real_time_tools": True
            }
        }
    except Exception as e:
        return {
            "status": "unhealthy",
            "error": str(e),
            "timestamp": datetime.now(timezone.utc).isoformat()
        }

@api_router.get("/performance-metrics")
async def get_performance_metrics():
    """Get enhanced system performance metrics showcasing Cerebras speed advantages"""
    
    # Get real-time performance stats
    perf_stats = get_performance_stats()
    
    # Get cache hit rates
    cache_stats = {
        "response_cache_size": len(response_cache),
        "conversation_cache_size": len(conversation_cache),
        "voice_cache_size": len(voice_cache),
        "tool_cache_size": len(tool_result_cache),
        "redis_connected": redis_client is not None
    }
    
    return {
        "real_time_performance": {
            "avg_response_time": round(perf_stats["avg_response_time"], 3),
            "min_response_time": round(perf_stats["min_response_time"], 3) if perf_stats["min_response_time"] else 0,
            "max_response_time": round(perf_stats["max_response_time"], 3) if perf_stats["max_response_time"] else 0,
            "p95_response_time": round(perf_stats["p95_response_time"], 3),
            "requests_processed": perf_stats["requests_processed"],
            "cache_efficiency": cache_stats
        },
        "cerebras_advantages": {
            "sub_second_responses": f"Cerebras enables {perf_stats['requests_processed']} sub-second agricultural advisories",
            "multi_step_reasoning": "Complex agricultural queries processed in under 2 seconds",
            "real_time_voice": "Voice-to-advisory pipeline optimized for rural connectivity",
            "speed_improvement": "34,560x faster than traditional agricultural advisory systems"
        },
        "system_capabilities": {
            "reasoning_types": ["simple", "moderate", "complex"],
            "max_reasoning_depth": 5,
            "supported_languages": ["en", "hi", "ta", "te", "mr", "bn", "gu", "kn", "ml", "pa"],
            "mcp_tools": ["crop-price", "web-search", "soil-health", "weather-predictor", "pest-identifier", "mandi-tracker"],
            "caching_layers": ["redis", "in-memory", "conversation", "voice", "tool-results"]
        },
        "performance_targets": {
            "simple_queries": "< 0.5 seconds",
            "moderate_queries": "< 1.0 seconds", 
            "complex_queries": "< 2.0 seconds",
            "voice_processing": "< 1.5 seconds end-to-end",
            "cache_hit_target": "> 30% for common queries"
        },
        "optimization_features": {
            "async_processing": "Non-blocking database operations",
            "connection_pooling": "50 concurrent MongoDB connections",
            "response_caching": "Multi-layer caching with TTL",
            "batch_operations": "Bulk database inserts for messages",
            "voice_optimization": "Parallel processing for voice workflows"
        }
    }

@api_router.get("/status/loading")
async def get_loading_status():
    """Get system loading status for better UX"""
    return {
        "system_ready": True,
        "services": {
            "agentic_reasoning": True,
            "voice_interface": True,
            "mcp_tools": True,
            "multilingual_support": True
        },
        "estimated_response_times": {
            "simple_query": 0.5,
            "complex_query": 1.5,
            "voice_processing": 2.0,
            "workflow_step": 1.0
        },
        "supported_languages": ["en", "hi", "pa", "ta", "te", "mr", "bn", "gu", "kn", "ml"],
        "available_tools": [
            "crop-price", "web-search", "soil-health", 
            "weather-predictor", "pest-identifier", "mandi-tracker"
        ]
    }

# Include router
app.include_router(api_router)

# Performance and Security Middleware
app.add_middleware(GZipMiddleware, minimum_size=1000)
app.add_middleware(
    TrustedHostMiddleware, 
    allowed_hosts=["localhost", "127.0.0.1", "*.agricultural-ai.com", "*.vercel.app", "*.onrender.com"]
)

# CORS Configuration - Allow Vercel frontend
cors_origins = os.environ.get('CORS_ORIGINS', '*').split(',')
# Always allow your Vercel domain
if 'https://crop-gpt.vercel.app' not in cors_origins and '*' not in cors_origins:
    cors_origins.append('https://crop-gpt.vercel.app')

app.add_middleware(
    CORSMiddleware,
    allow_credentials=True,
    allow_origins=cors_origins,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["*"],
    expose_headers=["*"],
)

<<<<<<< HEAD
=======
@app.on_event("startup")
async def startup_event():
    """Initialize database and services on startup"""
    global db
    db = await get_database()
    logger.info("Database initialized for all endpoints")

>>>>>>> c7ba531 (Initial push: migrate local codebase to KisanMitr)
@app.on_event("shutdown")
async def shutdown_db_client():
    client.close()
